name: Vertex MLOps Pipeline

on:
  push:
    branches: ["main"]
  workflow_dispatch: {}

jobs:
  vertex-mlops:
    runs-on: ubuntu-latest

    steps:

    # 1) Checkout du dépôt
    - name: Checkout
      uses: actions/checkout@v4

    # 2) Authentification GCP via secret JSON
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    # 3) Installation du CLI gcloud
    - name: Setup gcloud
      uses: google-github-actions/setup-gcloud@v2
      with:
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    # 4) Packaging du code Python (Vertex AI)
    - name: Build Python package for Vertex
      run: tar -czf src.tar.gz src setup.py

    # 5) Upload du package vers GCS
    - name: Upload package to GCS
      run: gsutil cp src.tar.gz gs://${{ secrets.GCS_BUCKET }}/code/src.tar.gz

    # 6) Installation des dépendances localement (GitHub Actions)
    - name: Install dependencies
      run: pip install -r requirements.txt

    # 7) Fetch + upload dataset (exécuté localement dans le runner)
    - name: Fetch & prepare dataset
      run: |
        RUN_ID=$(date +%s)
        echo "$RUN_ID" > run_id.txt
        python3 src/fetch_and_train.py --run_id $RUN_ID --pair BTC/USDT

    # 8) Lancement du job Vertex AI Training
    - name: Launch Vertex AI Job
      run: |
        RUN_ID=$(cat run_id.txt)
        echo "RUN_ID=$RUN_ID"

        JOB_ID=$(gcloud ai custom-jobs create \
          --region=${{ secrets.VERTEX_REGION }} \
          --display-name="train-${RUN_ID}" \
          --python-package-uris=gs://${{ secrets.GCS_BUCKET }}/code/src.tar.gz \
          --worker-pool-spec=machine-type=e2-standard-4,executor-image-uri=us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-11:latest,python-module=MLOPS_Crypto.train_lstm \
          --args=--data_prefix=gs://${{ secrets.GCS_BUCKET }}/ohlcv-data \
          --args=--pair=BTC_USDT \
          --args=--run_id=$RUN_ID \
          --format="value(name)" )

        echo "$JOB_ID" > job_id.txt
        echo "Launched job: $JOB_ID"

    # 9) Attendre Vertex (16 min)
    - name: Wait for Vertex AI Training Job
      run: |
        echo "Waiting 16 minutes while Vertex trains..."
        for i in {1..16}; do
          echo "Minute $i/16..."
          sleep 60
        done
        echo "Training should now be finished."

    # 10) Réinstallation des dépendances pour evaluate
    - name: Install local dependencies (evaluate)
      run: pip install -r requirements.txt

    # 10.5) Préparer dataset pour evaluate.py
    - name: Prepare dataset for evaluate.py
      run: |
        RUN_ID=$(cat run_id.txt)
        mkdir -p data data/prepared

        gsutil cp gs://${{ secrets.GCS_BUCKET }}/ohlcv-data/BTC_USDT_raw_${RUN_ID}.parquet data/raw.parquet

        python3 - <<EOF
        import pandas as pd
        df = pd.read_parquet("data/raw.parquet")
        df.to_csv("data/raw.csv", index=False)
        EOF

        python3 src/prepare.py data/raw.csv data/prepared

    # 11) DEBUG GCS + téléchargement du modèle + evaluate.py
    - name: Evaluate trained model
      run: |
        RUN_ID=$(cat run_id.txt)
        MODEL_DIR="local_model_${RUN_ID}"
        mkdir -p "$MODEL_DIR"

        echo "*** DEBUG 1: Listing model folders in GCS ***"
        gsutil ls gs://${{ secrets.GCS_BUCKET }}/ohlcv-data/models/

        MODEL_PATH=$(gsutil ls gs://${{ secrets.GCS_BUCKET }}/ohlcv-data/models/ | grep "BTC_USDT_${RUN_ID}_")

        if [ -z "$MODEL_PATH" ]; then
          echo "Model folder not found for RUN_ID=$RUN_ID"
          exit 1
        fi

        MODEL_PATH=$(echo "$MODEL_PATH" | sed 's:/*$::')
        echo "Found model folder: $MODEL_PATH"

        echo "*** DEBUG 2: Downloading model content ***"
        gsutil -m cp -r "$MODEL_PATH/*" "$MODEL_DIR/"

        echo "*** DEBUG 3: Local model folder content ***"
        ls -R "$MODEL_DIR"

        python3 src/evaluate.py "$MODEL_DIR" data/prepared

    # 12) Visualisation avancée (preds USD, zoom, future prediction)
    - name: Visualize trained model
      run: |
        RUN_ID=$(cat run_id.txt)
        python3 src/visualize_model.py \
          --bucket ${{ secrets.GCS_BUCKET }} \
          --gcs_path ohlcv-data \
          --run_id $RUN_ID

    # 13) Upload FINAL des graphes (evaluate + visualize_model)
    - name: Upload evaluation plots
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-plots
        path: |
          evaluation/
          evaluation/plots_gcs/
