name: Vertex MLOps Pipeline

on:
  push:
    branches: ["main"]
  workflow_dispatch: {}

jobs:
  vertex-mlops:
    runs-on: ubuntu-latest

    steps:
    # 1) Checkout du repo
    - name: Checkout
      uses: actions/checkout@v4

    # 2) Authentification Google Cloud
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Setup gcloud
      uses: google-github-actions/setup-gcloud@v2
      with:
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    # 3) Build du package Python (tar.gz) pour Vertex
    - name: Build Python package for Vertex
      run: tar -czf src.tar.gz src setup.py

    # 4) Upload du package vers GCS
    - name: Upload package to GCS
      run: gsutil cp src.tar.gz gs://${{ secrets.GCS_BUCKET }}/code/src.tar.gz

    # 5) Installation dépendances locales
    - name: Install dependencies
      run: pip install -r requirements.txt

    # 6) Génération dataset local + upload
    - name: Fetch & prepare dataset
      run: |
        RUN_ID=$(date +%s)
        echo "$RUN_ID" > run_id.txt
        python3 src/fetch_and_train.py --run_id $RUN_ID --pair BTC/USDT

    # 7) Lancement job Vertex
    - name: Launch Vertex AI Job
      run: |
        RUN_ID=$(cat run_id.txt)
        echo "RUN_ID=$RUN_ID"

        gcloud ai custom-jobs create \
          --region=${{ secrets.VERTEX_REGION }} \
          --display-name="train-${RUN_ID}" \
          --python-package-uris=gs://${{ secrets.GCS_BUCKET }}/code/src.tar.gz \
          --worker-pool-spec=machine-type=e2-standard-4,executor-image-uri=us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-11:latest,python-module=MLOPS_Crypto.train_lstm \
          --args=--data_prefix=gs://${{ secrets.GCS_BUCKET }}/ohlcv-data \
          --args=--pair=BTC_USDT \
          --args=--run_id=$RUN_ID

    # 8) Attendre la fin réelle du job vertex (fix critique)
    - name: Wait for Vertex AI Training Job
      run: |
        RUN_ID=$(cat run_id.txt)
        echo "Waiting for Vertex training job train-${RUN_ID}"

        JOB_ID=$(gcloud ai custom-jobs list \
          --region=${{ secrets.VERTEX_REGION }} \
          --format="value(name)" \
          --filter="displayName=train-${RUN_ID}")

        echo "Training job ID: $JOB_ID"
        echo "Streaming logs..."
        gcloud ai custom-jobs stream-logs $JOB_ID --region=${{ secrets.VERTEX_REGION }}

        echo "Checking final job status..."
        while true; do
          STATUS=$(gcloud ai custom-jobs describe $JOB_ID \
            --region=${{ secrets.VERTEX_REGION }} \
            --format="value(state)")
          
          echo "STATUS = $STATUS"
          
          if [[ "$STATUS" == "JOB_STATE_SUCCEEDED" ]]; then
            echo "Training completed!"
            break
          fi
          
          if [[ "$STATUS" == "JOB_STATE_FAILED" || "$STATUS" == "JOB_STATE_CANCELLED" ]]; then
            echo "Training failed!"
            exit 1
          fi

          echo "Still running... waiting 15 seconds."
          sleep 15
        done

    # 9) Installer deps localement pour visualisation
    - name: Install local dependencies
      run: pip install -r requirements.txt

    # 10) Visualisation locale du modèle entraîné
    - name: Visualize trained model
      run: |
        RUN_ID=$(cat run_id.txt)
        python3 src/visualize_model.py \
          --bucket ${{ secrets.GCS_BUCKET }} \
          --gcs_path ohlcv-data \
          --lookback 30 \
          --run_id $RUN_ID

    # 11) Upload des graphes
    - name: Upload evaluation plots
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-plots
        path: evaluation/
