name: Evaluate Only

on:
  workflow_dispatch:
    inputs:
      run_id:
        description: "RUN_ID du modèle à évaluer"
        required: true

jobs:
  evaluate-only:
    runs-on: ubuntu-latest

    steps:

    - name: Checkout
      uses: actions/checkout@v4

    - name: Install jq
      run: sudo apt-get install -y jq

    - name: Auth Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Setup gcloud
      uses: google-github-actions/setup-gcloud@v2
      with:
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    - name: Install dependencies
      run: pip install -r requirements.txt

    # 1) Télécharger modèle + lookback
    - name: Download model
      run: |
        RUN_ID="${{ github.event.inputs.run_id }}"
        echo "RUN_ID=$RUN_ID"

        MODEL_DIR="local_model_${RUN_ID}"
        mkdir -p "$MODEL_DIR"

        echo "Searching model folder..."
        MODEL_PATH=$(gsutil ls gs://${{ secrets.GCS_BUCKET }}/ohlcv-data/models/ | grep "BTC_USDT_${RUN_ID}_")

        if [ -z "$MODEL_PATH" ]; then
          echo "Model folder not found"
          exit 1
        fi

        MODEL_PATH=$(echo "$MODEL_PATH" | sed 's:/*$::')
        echo "Found model: $MODEL_PATH"

        echo "Downloading model..."
        gsutil -m cp -r "$MODEL_PATH/*" "$MODEL_DIR/"

        echo "Extracting lookback..."
        LOOKBACK=$(jq ".lookback" "$MODEL_DIR/model_config.json")
        echo "LOOKBACK=$LOOKBACK"

    # 2) Préparation du dataset avec lookback synchronisé
    - name: Prepare dataset
      run: |
        RUN_ID="${{ github.event.inputs.run_id }}"
        echo "Preparing dataset for RUN_ID=$RUN_ID"

        mkdir -p data data/prepared

        gsutil cp gs://${{ secrets.GCS_BUCKET }}/ohlcv-data/BTC_USDT_raw_${RUN_ID}.parquet data/raw.parquet

        python3 <<EOF
        import pandas as pd
        df = pd.read_parquet("data/raw.parquet")
        df.to_csv("data/raw.csv", index=False)
        EOF

        python3 src/prepare.py data/raw.csv data/prepared --model_dir "local_model_${RUN_ID}"

    # 3) Debug
    - name: Debug model folder
      run: |
        RUN_ID="${{ github.event.inputs.run_id }}"
        ls -R "local_model_${RUN_ID}"

    # 4) Evaluate
    - name: Evaluate
      run: |
        RUN_ID="${{ github.event.inputs.run_id }}"
        python3 src/evaluate.py "local_model_${RUN_ID}" data/prepared

    # 5) Visualize (plots_gcs correctement créés)
    - name: Visualize
      run: |
        RUN_ID="${{ github.event.inputs.run_id }}"

        mkdir -p evaluation/plots_gcs

        echo "*** BEFORE VISUALIZE ***"
        ls -R evaluation/

        python3 src/visualize_model.py \
          --bucket "${{ secrets.GCS_BUCKET }}" \
          --gcs_path "ohlcv-data" \
          --run_id "$RUN_ID"

        echo "*** AFTER VISUALIZE ***"
        ls -R evaluation/

    # 6) Upload final
    - name: Upload evaluation plots
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-plots
        path: |
          evaluation/
          evaluation/plots_gcs/

